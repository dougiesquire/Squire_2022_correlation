/g/data/xv83/users/ds0092/software/miniconda3/envs/squire_2022_correlation/lib/python3.10/site-packages/distributed/cli/dask_worker.py:333: FutureWarning: The --nprocs flag will be removed in a future release. It has been renamed to --nworkers.
  warnings.warn(
2022-07-08 13:11:46,815 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.0.128.13:38309'
2022-07-08 13:11:46,846 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.0.128.13:42267'
2022-07-08 13:11:46,847 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.0.128.13:39793'
2022-07-08 13:11:46,864 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.0.128.13:41621'
2022-07-08 13:12:02,053 - distributed.worker - INFO -       Start worker at:    tcp://10.0.128.13:36637
2022-07-08 13:12:02,054 - distributed.worker - INFO -          Listening to:    tcp://10.0.128.13:36637
2022-07-08 13:12:02,053 - distributed.worker - INFO -       Start worker at:    tcp://10.0.128.13:40875
2022-07-08 13:12:02,054 - distributed.worker - INFO -          dashboard at:          10.0.128.13:33081
2022-07-08 13:12:02,054 - distributed.worker - INFO -       Start worker at:    tcp://10.0.128.13:36987
2022-07-08 13:12:02,054 - distributed.worker - INFO -          Listening to:    tcp://10.0.128.13:40875
2022-07-08 13:12:02,054 - distributed.worker - INFO - Waiting to connect to:   tcp://10.0.128.137:40431
2022-07-08 13:12:02,054 - distributed.worker - INFO -          Listening to:    tcp://10.0.128.13:36987
2022-07-08 13:12:02,054 - distributed.worker - INFO -          dashboard at:          10.0.128.13:38031
2022-07-08 13:12:02,054 - distributed.worker - INFO - -------------------------------------------------
2022-07-08 13:12:02,054 - distributed.worker - INFO -          dashboard at:          10.0.128.13:38401
2022-07-08 13:12:02,054 - distributed.worker - INFO - Waiting to connect to:   tcp://10.0.128.137:40431
2022-07-08 13:12:02,054 - distributed.worker - INFO -               Threads:                          4
2022-07-08 13:12:02,054 - distributed.worker - INFO - -------------------------------------------------
2022-07-08 13:12:02,054 - distributed.worker - INFO - Waiting to connect to:   tcp://10.0.128.137:40431
2022-07-08 13:12:02,054 - distributed.worker - INFO -               Threads:                          4
2022-07-08 13:12:02,054 - distributed.worker - INFO -                Memory:                  10.94 GiB
2022-07-08 13:12:02,054 - distributed.worker - INFO - -------------------------------------------------
2022-07-08 13:12:02,054 - distributed.worker - INFO -               Threads:                          4
2022-07-08 13:12:02,054 - distributed.worker - INFO -                Memory:                  10.94 GiB
2022-07-08 13:12:02,054 - distributed.worker - INFO -       Local Directory: /local/v14/ds0092/tmp/dask-worker-space/worker-g7mj0orj
2022-07-08 13:12:02,054 - distributed.worker - INFO -       Local Directory: /local/v14/ds0092/tmp/dask-worker-space/worker-j3dczvs9
2022-07-08 13:12:02,054 - distributed.worker - INFO -                Memory:                  10.94 GiB
2022-07-08 13:12:02,055 - distributed.worker - INFO - -------------------------------------------------
2022-07-08 13:12:02,055 - distributed.worker - INFO -       Local Directory: /local/v14/ds0092/tmp/dask-worker-space/worker-9cb293oh
2022-07-08 13:12:02,055 - distributed.worker - INFO - -------------------------------------------------
2022-07-08 13:12:02,055 - distributed.worker - INFO - -------------------------------------------------
2022-07-08 13:12:02,056 - distributed.worker - INFO -       Start worker at:    tcp://10.0.128.13:33691
2022-07-08 13:12:02,056 - distributed.worker - INFO -          Listening to:    tcp://10.0.128.13:33691
2022-07-08 13:12:02,057 - distributed.worker - INFO -          dashboard at:          10.0.128.13:36197
2022-07-08 13:12:02,057 - distributed.worker - INFO - Waiting to connect to:   tcp://10.0.128.137:40431
2022-07-08 13:12:02,057 - distributed.worker - INFO - -------------------------------------------------
2022-07-08 13:12:02,057 - distributed.worker - INFO -               Threads:                          4
2022-07-08 13:12:02,057 - distributed.worker - INFO -                Memory:                  10.94 GiB
2022-07-08 13:12:02,057 - distributed.worker - INFO -       Local Directory: /local/v14/ds0092/tmp/dask-worker-space/worker-p3au5mkj
2022-07-08 13:12:02,058 - distributed.worker - INFO - -------------------------------------------------
2022-07-08 13:12:02,077 - distributed.worker - INFO -         Registered to:   tcp://10.0.128.137:40431
2022-07-08 13:12:02,077 - distributed.worker - INFO - -------------------------------------------------
2022-07-08 13:12:02,078 - distributed.core - INFO - Starting established connection
2022-07-08 13:12:02,079 - distributed.worker - INFO -         Registered to:   tcp://10.0.128.137:40431
2022-07-08 13:12:02,079 - distributed.worker - INFO - -------------------------------------------------
2022-07-08 13:12:02,080 - distributed.core - INFO - Starting established connection
2022-07-08 13:12:02,080 - distributed.worker - INFO -         Registered to:   tcp://10.0.128.137:40431
2022-07-08 13:12:02,081 - distributed.worker - INFO - -------------------------------------------------
2022-07-08 13:12:02,082 - distributed.core - INFO - Starting established connection
2022-07-08 13:12:02,082 - distributed.worker - INFO -         Registered to:   tcp://10.0.128.137:40431
2022-07-08 13:12:02,082 - distributed.worker - INFO - -------------------------------------------------
2022-07-08 13:12:02,084 - distributed.core - INFO - Starting established connection
2022-07-08 13:12:58,479 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2022-07-08 13:12:58,480 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2022-07-08 13:12:58,480 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2022-07-08 13:13:01,548 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2022-07-08 13:13:01,548 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2022-07-08 13:13:01,548 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2022-07-08 13:13:01,549 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2022-07-08 13:15:21,249 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2022-07-08 13:15:40,629 - distributed.utils_perf - INFO - full garbage collection released 37.99 MiB from 1404 reference cycles (threshold: 9.54 MiB)
2022-07-08 13:16:23,669 - distributed.utils_perf - INFO - full garbage collection released 69.62 MiB from 1011 reference cycles (threshold: 9.54 MiB)
slurmstepd: error: *** JOB 49733 ON ood-n13 CANCELLED AT 2022-07-08T13:45:49 ***
2022-07-08 13:45:49,574 - distributed.worker - INFO - Stopping worker at tcp://10.0.128.13:33691
2022-07-08 13:45:49,573 - distributed.worker - INFO - Stopping worker at tcp://10.0.128.13:36987
2022-07-08 13:45:49,573 - distributed.worker - INFO - Stopping worker at tcp://10.0.128.13:40875
2022-07-08 13:45:49,574 - distributed.worker - INFO - Stopping worker at tcp://10.0.128.13:36637
2022-07-08 13:45:49,578 - distributed.worker - INFO - Connection to scheduler broken. Closing without reporting. ID: Worker-c289ce6d-8991-4e41-9cb0-c8c6ee6271a0 Address tcp://10.0.128.13:36987 Status: Status.closing
2022-07-08 13:45:49,578 - distributed.worker - INFO - Connection to scheduler broken. Closing without reporting. ID: Worker-b32dc7ce-618e-41c7-b730-b2a3263d2491 Address tcp://10.0.128.13:33691 Status: Status.closing
2022-07-08 13:45:49,579 - distributed.worker - INFO - Connection to scheduler broken. Closing without reporting. ID: Worker-e98be2a5-a3f2-4e56-b867-e8670afae348 Address tcp://10.0.128.13:40875 Status: Status.closing
2022-07-08 13:45:49,580 - distributed.worker - INFO - Connection to scheduler broken. Closing without reporting. ID: Worker-0063a631-1c3c-43e8-ac17-3127e9e90e0d Address tcp://10.0.128.13:36637 Status: Status.closing
2022-07-08 13:45:49,579 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.0.128.13:54086 remote=tcp://10.0.128.137:40431>
Traceback (most recent call last):
  File "/g/data/xv83/users/ds0092/software/miniconda3/envs/squire_2022_correlation/lib/python3.10/site-packages/distributed/batched.py", line 97, in _background_send
    nbytes = yield self.comm.write(
  File "/g/data/xv83/users/ds0092/software/miniconda3/envs/squire_2022_correlation/lib/python3.10/site-packages/tornado/gen.py", line 762, in run
    value = future.result()
  File "/g/data/xv83/users/ds0092/software/miniconda3/envs/squire_2022_correlation/lib/python3.10/site-packages/distributed/comm/tcp.py", line 273, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2022-07-08 13:45:49,580 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.0.128.13:54084 remote=tcp://10.0.128.137:40431>
Traceback (most recent call last):
  File "/g/data/xv83/users/ds0092/software/miniconda3/envs/squire_2022_correlation/lib/python3.10/site-packages/distributed/batched.py", line 97, in _background_send
    nbytes = yield self.comm.write(
  File "/g/data/xv83/users/ds0092/software/miniconda3/envs/squire_2022_correlation/lib/python3.10/site-packages/tornado/gen.py", line 762, in run
    value = future.result()
  File "/g/data/xv83/users/ds0092/software/miniconda3/envs/squire_2022_correlation/lib/python3.10/site-packages/distributed/comm/tcp.py", line 273, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2022-07-08 13:45:49,580 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.0.128.13:54080 remote=tcp://10.0.128.137:40431>
Traceback (most recent call last):
  File "/g/data/xv83/users/ds0092/software/miniconda3/envs/squire_2022_correlation/lib/python3.10/site-packages/distributed/batched.py", line 97, in _background_send
    nbytes = yield self.comm.write(
  File "/g/data/xv83/users/ds0092/software/miniconda3/envs/squire_2022_correlation/lib/python3.10/site-packages/tornado/gen.py", line 762, in run
    value = future.result()
  File "/g/data/xv83/users/ds0092/software/miniconda3/envs/squire_2022_correlation/lib/python3.10/site-packages/distributed/comm/tcp.py", line 273, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2022-07-08 13:45:49,579 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.0.128.13:54082 remote=tcp://10.0.128.137:40431>
Traceback (most recent call last):
  File "/g/data/xv83/users/ds0092/software/miniconda3/envs/squire_2022_correlation/lib/python3.10/site-packages/distributed/batched.py", line 97, in _background_send
    nbytes = yield self.comm.write(
  File "/g/data/xv83/users/ds0092/software/miniconda3/envs/squire_2022_correlation/lib/python3.10/site-packages/tornado/gen.py", line 762, in run
    value = future.result()
  File "/g/data/xv83/users/ds0092/software/miniconda3/envs/squire_2022_correlation/lib/python3.10/site-packages/distributed/comm/tcp.py", line 273, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2022-07-08 13:45:49,684 - distributed.nanny - INFO - Worker closed
2022-07-08 13:45:49,685 - distributed.nanny - INFO - Worker closed
2022-07-08 13:45:49,686 - distributed.nanny - ERROR - Worker process died unexpectedly
2022-07-08 13:45:49,686 - distributed.nanny - INFO - Worker closed
2022-07-08 13:45:49,688 - distributed.nanny - ERROR - Worker process died unexpectedly
2022-07-08 13:45:49,689 - distributed.nanny - ERROR - Worker process died unexpectedly
2022-07-08 13:45:49,694 - distributed.nanny - INFO - Worker closed
2022-07-08 13:45:49,696 - distributed.nanny - ERROR - Worker process died unexpectedly
